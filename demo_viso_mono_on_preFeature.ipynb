{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Rui Zhu (rzhu@eng.ucsd.edu)\n",
    "# For CSE152B Spring 2020 HW1\n",
    "# Apr 15, 2020\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "import viso2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import time\n",
    "import scipy.io as io\n",
    "import os.path as osp\n",
    "\n",
    "def errorMetric(RPred, RGt, TPred, TGt):\n",
    "    diffRot = (RPred - RGt)\n",
    "    diffTrans = (TPred - TGt)\n",
    "    errorRot = np.sqrt(np.sum(np.multiply(diffRot.reshape(-1), diffRot.reshape(-1))))\n",
    "    errorTrans = np.sqrt(np.sum(np.multiply(diffTrans.reshape(-1), diffTrans.reshape(-1))))\n",
    "\n",
    "    return errorRot, errorTrans\n",
    "\n",
    "if_vis = True # set to True to do the visualization per frame; the images will be saved at '.vis/'. Turn off if you just want the camera poses and errors\n",
    "if_on_screen = False # if True the visualization per frame is going to be displayed realtime on screen; if False there will be no display, but in both options the images will be saved\n",
    "\n",
    "# parameter settings (for an example, please download\n",
    "# dataset_path = '../dataset'\n",
    "dataset_path = '/datasets/cse152-252-sp20-public/dataset_SfM' # On the ``ieng6.ucsd.edu`` server\n",
    "img_dir      = os.path.join(dataset_path, 'sequences/00/image_0')\n",
    "gt_dir       = os.path.join(dataset_path, 'poses/00.txt')\n",
    "calibFile    = os.path.join(dataset_path, 'sequences/00/calib.txt')\n",
    "border       = 50\n",
    "gap          = 15\n",
    "suffix = 'superpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the camera calibration information\n",
    "with open(calibFile) as fid:\n",
    "    calibLines = fid.readlines()\n",
    "    calibLines = [calibLine.strip() for calibLine in calibLines]\n",
    "\n",
    "calibInfo = [float(calibStr) for calibStr in calibLines[0].split(' ')[1:]]\n",
    "# param = {'f': calibInfo[0], 'cu': calibInfo[2], 'cv': calibInfo[6]}\n",
    "\n",
    "# Load the ground-truth depth and rotation\n",
    "with open(gt_dir) as fid:\n",
    "    gtTr = [[float(TrStr) for TrStr in line.strip().split(' ')] for line in fid.readlines()]\n",
    "gtTr = np.asarray(gtTr).reshape(-1, 3, 4)\n",
    "\n",
    "first_frame  = 0\n",
    "last_frame   = 300\n",
    "\n",
    "# init visual odometry\n",
    "params = viso2.Mono_parameters()\n",
    "params.calib.f = calibInfo[0]\n",
    "params.calib.cu = calibInfo[2]\n",
    "params.calib.cv = calibInfo[6]\n",
    "params.height = 1.6\n",
    "params.pitch = -0.08\n",
    "\n",
    "first_frame  = 0\n",
    "last_frame   = 300\n",
    "\n",
    "# init transformation matrix array\n",
    "Tr_total = []\n",
    "Tr_total_np = []\n",
    "Tr_total.append(viso2.Matrix_eye(4))\n",
    "Tr_total_np.append(np.eye(4))\n",
    "\n",
    "# init viso module\n",
    "visoMono = viso2.VisualOdometryMono(params)\n",
    "\n",
    "\n",
    "if if_vis:\n",
    "    save_path = 'vis_preFeature'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(10, 15))\n",
    "    ax1 = plt.subplot(211)\n",
    "    ax1.axis('off')\n",
    "    ax2 = plt.subplot(212)\n",
    "    ax2.set_xticks(np.arange(-100, 100, step=10))\n",
    "    ax2.set_yticks(np.arange(-500, 500, step=10))\n",
    "    ax2.axis('equal')\n",
    "    ax2.grid()\n",
    "    if if_on_screen:\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all frames do\n",
    "if_replace = False\n",
    "errorTransSum = 0\n",
    "errorRotSum = 0\n",
    "errorRot_list = []\n",
    "errorTrans_list =[]\n",
    "\n",
    "for frame in range(first_frame, last_frame):\n",
    "    # 1-based index\n",
    "    k = frame-first_frame+1\n",
    "\n",
    "    # read current images\n",
    "    I = imread(os.path.join(img_dir, '%06d.png'%frame))\n",
    "    feature = np.load( osp.join(img_dir, '%06d_%s.npy' % (frame, suffix) ) )\n",
    "    feature = np.ascontiguousarray(feature )\n",
    "\n",
    "    assert(len(I.shape) == 2) # should be grayscale\n",
    "    feature = feature.astype(np.float32 )\n",
    "\n",
    "    # compute egomotion\n",
    "    process_result = visoMono.process_frame_preFeat(I, feature, if_replace)\n",
    "\n",
    "    Tr = visoMono.getMotion()\n",
    "    matrixer = viso2.Matrix(Tr)\n",
    "    Tr_np = np.zeros((4, 4) )\n",
    "    Tr.toNumpy(Tr_np) # so awkward...\n",
    "\n",
    "    # accumulate egomotion, starting with second frame\n",
    "    if k > 1:\n",
    "        if process_result is False:\n",
    "            if_replace = True\n",
    "            Tr_total.append(Tr_total[-1])\n",
    "            Tr_total_np.append(Tr_total_np[-1])\n",
    "        else:\n",
    "            if_replace = False\n",
    "            Tr_total.append(Tr_total[-1] * viso2.Matrix_inv(Tr))\n",
    "            Tr_total_np.append(Tr_total_np[-1] @ np.linalg.inv(Tr_np)) # should be the same\n",
    "            print(Tr_total_np[-1])\n",
    "\n",
    "    # output statistics\n",
    "    num_matches = visoMono.getNumberOfMatches()\n",
    "    num_inliers = visoMono.getNumberOfInliers()\n",
    "    matches = visoMono.getMatches()\n",
    "    matches_np = np.empty([4, matches.size()])\n",
    "\n",
    "    for i,m in enumerate(matches):\n",
    "        matches_np[:, i] = (m.u1p, m.v1p, m.u1c, m.v1c)\n",
    "\n",
    "    if if_vis:\n",
    "        # update image\n",
    "        ax1.clear()\n",
    "        ax1.imshow(I, cmap='gray', vmin=0, vmax=255)\n",
    "        if num_matches != 0:\n",
    "            for n in range(num_matches):\n",
    "                ax1.plot([matches_np[0, n], matches_np[2, n]], [matches_np[1, n], matches_np[3, n]])\n",
    "        ax1.set_title('Frame %d'%frame)\n",
    "\n",
    "        # update trajectory\n",
    "        if k > 1:\n",
    "            ax2.plot([Tr_total_np[k-2][0, 3], Tr_total_np[k-1][0, 3]], \\\n",
    "                [Tr_total_np[k-2][2, 3], Tr_total_np[k-1][2, 3]], 'b.-', linewidth=1)\n",
    "            ax2.plot([gtTr[k-2][0, 3], gtTr[k-1][0, 3]], \\\n",
    "                [gtTr[k-2][2, 3], gtTr[k-1][2, 3]], 'r.-', linewidth=1)\n",
    "        ax2.set_title('Blue: estimated trajectory; Red: ground truth trejectory')\n",
    "\n",
    "        plt.draw()\n",
    "\n",
    "    # Compute rotation\n",
    "    Rpred_p = Tr_total_np[k-2][0:3, 0:3]\n",
    "    Rpred_c = Tr_total_np[k-1][0:3, 0:3]\n",
    "    Rpred = Rpred_c.transpose() @ Rpred_p\n",
    "    Rgt_p = np.squeeze(gtTr[k-2, 0:3, 0:3])\n",
    "    Rgt_c = np.squeeze(gtTr[k-1, 0:3, 0:3])\n",
    "    Rgt = Rgt_c.transpose() @ Rgt_p\n",
    "    # Compute translation\n",
    "    Tpred_p = Tr_total_np[k-2][0:3, 3:4]\n",
    "    Tpred_c = Tr_total_np[k-1][0:3, 3:4]\n",
    "    Tpred = Tpred_c - Tpred_p\n",
    "    Tgt_p = gtTr[k-2, 0:3, 3:4]\n",
    "    Tgt_c = gtTr[k-1, 0:3, 3:4]\n",
    "    Tgt = Tgt_c - Tgt_p\n",
    "    # Compute errors\n",
    "    errorRot, errorTrans = errorMetric(Rpred, Rgt, Tpred, Tgt)\n",
    "    errorRotSum = errorRotSum + errorRot\n",
    "    errorTransSum = errorTransSum + errorTrans\n",
    "    # errorRot_list.append(errorRot)\n",
    "    # errorTrans_list.append(errorTrans)\n",
    "    print('Mean Error Rotation: %.5f'%(errorRotSum / (k-1)))\n",
    "    print('Mean Error Translation: %.5f'%(errorTransSum / (k-1)))\n",
    "\n",
    "\n",
    "\n",
    "    print('== [Result] Frame: %d, Matches %d, Inliers: %.2f'%(frame, num_matches, 100*num_inliers/(num_matches+1e-8)))\n",
    "\n",
    "    if if_vis:\n",
    "        # input('Paused; Press Enter to continue') # Option 1: Manually pause and resume\n",
    "        if if_on_screen:\n",
    "            plt.pause(0.1) # Or Option 2: enable to this to auto pause for a while after daring to enable animation in case of a delay in drawing\n",
    "        vis_path = os.path.join(save_path, 'frame%03d.jpg'%frame)\n",
    "        fig.savefig(vis_path)\n",
    "        print('Saved at %s'%vis_path)\n",
    "\n",
    "\n",
    "# input('Press Enter to exit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:libvisio] *",
   "language": "python",
   "name": "conda-env-libvisio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
